# Adversarial Encryption and Reconstruction of Medical Images

This project explores **adversarial attacks** as a novel encryption mechanism for medical images, and investigates methods for reconstructing both the original images and diagnostic labels. Instead of treating adversarial perturbations as threats, this work repurposes them as a **privacy-preserving tool** for securing sensitive medical data.

## Overview
- **Dataset**: NIH Chest X-ray dataset (112,120 frontal-view images, 30,805 patients).
- **Encryption**: Adversarial attacks (FGSM ‚Äì white-box, HopSkipJump & Square ‚Äì black-box).
- **Reconstruction**:
  - Variational Autoencoder (VAE) architectures
  - Simple denoisers for image restoration
  - Classifiers for label recovery
  - A joint model combining image + label reconstruction
- **Evaluation Metrics**:
  - Image quality: **PSNR, SSIM**
  - Classification: **Accuracy, Precision, Recall**

## Motivation
Medical images are highly sensitive, containing both identifiable and diagnostically critical information.  
Traditional encryption methods protect privacy but render images unreadable until fully decrypted, disrupting clinical workflows.  
This project demonstrates how adversarial perturbations can **encrypt images invisibly**:  
- For unauthorized users ‚Üí encrypted images look unchanged but mislead AI systems.  
- For authorized users ‚Üí reconstruction models recover the original image and labels, maintaining clinical usability.  

## üõ†Ô∏è Project Structure

